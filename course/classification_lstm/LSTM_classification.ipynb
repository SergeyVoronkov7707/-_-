{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea94eda4",
   "metadata": {},
   "source": [
    "Задание  \n",
    "Данные берем отызывы за лето  \n",
    "На вебинаре мы говорили, что долгое время CNN и RNN архитектуры были конурируещими выяснить какая архитектура больше подходит для нашей задачи  \n",
    "1. построить свёрточные архитектуры  \n",
    "2. построить различные архитектуры с RNN  \n",
    "3. построить совместные архитектуры CNN -> RNN или (RNN -> CNN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2319ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуем запрограммировать простую рекурентную сеть. Возьмем датасет с прошлого занятия\n",
    "\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_val = pd.read_csv(\"data/val.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4f01a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204150</td>\n",
       "      <td>Тектоника и рельеф-самое ужасное в мире мучение(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204151</td>\n",
       "      <td>Ходили запускать шар желаний, но у нас не полу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204152</td>\n",
       "      <td>Хочу лето только ради того, что бы направить н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204153</td>\n",
       "      <td>RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204154</td>\n",
       "      <td>RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  204150   Тектоника и рельеф-самое ужасное в мире мучение(\n",
       "1  204151  Ходили запускать шар желаний, но у нас не полу...\n",
       "2  204152  Хочу лето только ради того, что бы направить н...\n",
       "3  204153  RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...\n",
       "4  204154  RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88c61931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60fffbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cobj(df):\n",
    "        if df == 1:\n",
    "            return 'positive'\n",
    "        else:\n",
    "            return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d558f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['class_obj'] = df_train['class'].apply(cobj)\n",
    "df_val['class_obj'] = df_val['class'].apply(cobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83f02be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181467, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0ad555",
   "metadata": {},
   "source": [
    "обработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd80f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def funk_del(input_txt):\n",
    "    pattern = \"@[\\w]*\"\n",
    "    if re.findall(pattern, input_txt):\n",
    "        return re.sub(pattern, ' ', input_txt)\n",
    "    else:\n",
    "        return re.sub(pattern, ' ', input_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b14fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt =  re.sub(r'[^а-яА-Я]', ' ', txt) # Заменим спец. символы на пробелы\n",
    "    txt = funk_del(txt) # Удалим @word из всех твитов\n",
    "#     txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db2a908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_label_train = df_train['class_obj'].factorize()\n",
    "sentiment_label_val = df_val['class_obj'].factorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8781a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D,GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking, MaxPool1D, Normalization\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "# from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9cbcb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 220 artists>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, _, hist = plt.hist(df_train.text.apply(lambda text: len(text.split())), bins='auto')\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4412b937",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c61381af",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values\n",
    "text_corpus_test = df_test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e81d45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181467\n",
      "22683\n",
      "22684\n"
     ]
    }
   ],
   "source": [
    "print(len(text_corpus_train))\n",
    "print(len(text_corpus_valid))\n",
    "print(len(text_corpus_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce89ae2c",
   "metadata": {},
   "source": [
    "токенизация, выделение в переменную максимальное кол-во токенов, максимальная длина твита"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7eaed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=word_count, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)\n",
    "X_test = pad_sequences(sequences_test, maxlen=training_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c69c5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96560, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count, training_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dca9e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "668368a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def exec_time(start, end):\n",
    "    diff_time = end - start\n",
    "    m, s = divmod(diff_time, 60)\n",
    "    h, m = divmod(m, 60)\n",
    "    s,m,h = int(round(s, 0)), int(round(m, 0)), int(round(h, 0))\n",
    "    return \"{0:02d}:{1:02d}:{2:02d}\".format(h, m, s)\n",
    "#    print(\"Execution Time: \" + \"{0:02d}:{1:02d}:{2:02d}\".format(h, m, s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64676544",
   "metadata": {},
   "source": [
    "## lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13fd806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1853df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 31, 31)            2993360   \n",
      "                                                                 \n",
      " masking_3 (Masking)         (None, 31, 31)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                24576     \n",
      "                                                                 \n",
      " normalization_3 (Normalizat  (None, 64)               3         \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,018,600\n",
      "Trainable params: 3,018,597\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "\n",
    "model_lstm.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=X_train.shape[1],\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model_lstm.add(Masking(mask_value=0.0))\n",
    "model_lstm.add(LSTM(64, dropout=0.5, recurrent_dropout=0.5))\n",
    "model_lstm.add(Normalization(axis=None))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(10, activation='LeakyReLU'))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "daf4ccf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0d6cd8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "993/993 [==============================] - 59s 59ms/step - loss: 0.3691 - accuracy: 0.8221 - val_loss: 0.7270 - val_accuracy: 0.7068\n",
      "Epoch 2/10\n",
      "993/993 [==============================] - 57s 57ms/step - loss: 0.3582 - accuracy: 0.8271 - val_loss: 0.7741 - val_accuracy: 0.7048\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model_lstm.fit(X_train, sentiment_label_train[0],\n",
    "                    batch_size=128,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.3,\n",
    "                    callbacks=[early_stopping])\n",
    "end = time.time()\n",
    "time_con = exec_time(start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b370249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as leaky_re_lu_3_layer_call_fn, leaky_re_lu_3_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm\\assets\n"
     ]
    }
   ],
   "source": [
    "model_lstm.save('lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a9361ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b82f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ff3c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea8a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c40cb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# saving\n",
    "with open('sentiment_label_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(sentiment_label_train, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39cb65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('sentiment_label_train.pickle', 'rb') as handle:\n",
    "    sentiment_label_train12 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e52a73b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хороший погода\n"
     ]
    }
   ],
   "source": [
    "st_word =\"хорошая погода\"\n",
    "print(preprocess_text(st_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5381837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[259]]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0 259]]\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word =\"не очень погода\"\n",
    "test_word = preprocess_text(test_word)\n",
    "tw = tokenizer1.texts_to_sequences([test_word])\n",
    "print(tw)\n",
    "tw = pad_sequences(tw,maxlen=31)\n",
    "print(tw)\n",
    "prediction = int(model_lstm.predict(tw).round().item())\n",
    "# prediction = int(np.array([[0.75]]).round().item())\n",
    "# # print(type(model_lstm.predict(tw)))\n",
    "# print(prediction)\n",
    "sentiment_label_train12[1][prediction]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
